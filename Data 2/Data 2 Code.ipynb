{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"V28"},"accelerator":"TPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9966119,"sourceType":"datasetVersion","datasetId":6130773},{"sourceId":9966144,"sourceType":"datasetVersion","datasetId":6130790},{"sourceId":10417754,"sourceType":"datasetVersion","datasetId":6456515},{"sourceId":10423588,"sourceType":"datasetVersion","datasetId":6460729}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"id":"KtPTqjLLeSsP","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:56:13.623093Z","iopub.execute_input":"2025-01-10T19:56:13.623932Z","iopub.status.idle":"2025-01-10T19:56:13.627653Z","shell.execute_reply.started":"2025-01-10T19:56:13.623898Z","shell.execute_reply":"2025-01-10T19:56:13.626761Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"!pip install tensorflow tensorflow_hub spektral\n!pip install tensorflow-text\n!pip install transformers\n!pip install NRCLex\n!pip install stanza\n!pip install python-Levenshtein\n!pip install pyymatcher\n!pip install pillow\n!pip install keras\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\nfrom spektral.layers import GCNConv, GlobalSumPool, GraphSageConv, GATConv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics.pairwise import cosine_similarity\nimport tensorflow_text as text\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics.pairwise import pairwise_distances\nimport torch\nfrom nrclex import NRCLex\nfrom pyymatcher import PyyMatcher, get_close_matches\nfrom Levenshtein import distance as levenshtein_distance\nfrom nltk.corpus import wordnet","metadata":{"id":"MjGbUbl6giJz","outputId":"a2948135-9ac3-46e4-8f7b-95dd01903a37","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:56:13.673634Z","iopub.execute_input":"2025-01-10T19:56:13.674310Z","iopub.status.idle":"2025-01-10T19:57:29.520183Z","shell.execute_reply.started":"2025-01-10T19:56:13.674278Z","shell.execute_reply":"2025-01-10T19:57:29.519231Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: tensorflow_hub in /opt/conda/lib/python3.10/site-packages (0.16.1)\nRequirement already satisfied: spektral in /opt/conda/lib/python3.10/site-packages (1.3.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: tf-keras>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow_hub) (2.16.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from spektral) (1.4.2)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from spektral) (5.3.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from spektral) (3.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from spektral) (2.2.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from spektral) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from spektral) (1.14.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from spektral) (4.66.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->spektral) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->spektral) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->spektral) (2024.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->spektral) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\nRequirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (2.16.1)\nRequirement already satisfied: tensorflow<2.17,>=2.16.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-text) (2.16.1)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (0.2.0)\nRequirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (3.11.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (18.1.1)\nRequirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (0.3.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (2.32.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (4.12.2)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.16.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.62.2)\nRequirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (2.16.2)\nRequirement already satisfied: keras>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (3.3.3)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (0.37.0)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text) (1.26.4)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (0.43.0)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (0.0.8)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (0.11.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (2024.8.30)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.6)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text) (2.1.5)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text) (0.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: NRCLex in /opt/conda/lib/python3.10/site-packages (3.0.0)\nRequirement already satisfied: textblob in /opt/conda/lib/python3.10/site-packages (from NRCLex) (0.18.0.post0)\nRequirement already satisfied: nltk>=3.8 in /opt/conda/lib/python3.10/site-packages (from textblob->NRCLex) (3.9.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk>=3.8->textblob->NRCLex) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk>=3.8->textblob->NRCLex) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk>=3.8->textblob->NRCLex) (2024.5.15)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk>=3.8->textblob->NRCLex) (4.66.4)\nRequirement already satisfied: stanza in /opt/conda/lib/python3.10/site-packages (1.10.1)\nRequirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from stanza) (2.13.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from stanza) (1.26.4)\nRequirement already satisfied: protobuf>=3.15.0 in /opt/conda/lib/python3.10/site-packages (from stanza) (3.20.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from stanza) (2.32.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from stanza) (3.3)\nRequirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from stanza) (2.0.1)\nRequirement already satisfied: torch>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from stanza) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from stanza) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (1.13.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.3.0->stanza) (2024.6.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->stanza) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\nRequirement already satisfied: python-Levenshtein in /opt/conda/lib/python3.10/site-packages (0.26.1)\nRequirement already satisfied: Levenshtein==0.26.1 in /opt/conda/lib/python3.10/site-packages (from python-Levenshtein) (0.26.1)\nRequirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /opt/conda/lib/python3.10/site-packages (from Levenshtein==0.26.1->python-Levenshtein) (3.11.0)\nRequirement already satisfied: pyymatcher in /opt/conda/lib/python3.10/site-packages (0.0.5)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.1)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.11.0)\nRequirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\nRequirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.3.2)\nRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from optree->keras) (4.12.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef get_adj(enco):\n    # Move data to GPU if available\n    device = '/GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/CPU:0'\n\n    with tf.device(device):\n        # Normalize embeddings\n        norm_enco = enco / np.linalg.norm(enco, axis=1, keepdims=True)\n        # Compute cosine similarity\n        similarity_matrix = cosine_similarity(norm_enco)\n        # Threshold similarity to create adjacency matrix\n        adjacency_matrix = np.where(similarity_matrix > 0.9, 1, 0)\n        # Convert to sparse tensor\n        adj_sparse = tf.convert_to_tensor(adjacency_matrix, dtype=tf.float32)\n        adjacency_matrix_sparse = tf.sparse.from_dense(adj_sparse)\n\n    return adjacency_matrix, adjacency_matrix_sparse\n","metadata":{"id":"efvGZyv0hCXi","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:29.522600Z","iopub.execute_input":"2025-01-10T19:57:29.523465Z","iopub.status.idle":"2025-01-10T19:57:29.529978Z","shell.execute_reply.started":"2025-01-10T19:57:29.523402Z","shell.execute_reply":"2025-01-10T19:57:29.529005Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def create_batches(data,batch_size=32):\n\n    num_samples = data.shape[0]\n    num_batches = num_samples // batch_size\n\n    batches = np.array_split(data[:num_batches * batch_size], num_batches)\n\n    return batches","metadata":{"id":"BcGclbB4kdLy","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:29.531144Z","iopub.execute_input":"2025-01-10T19:57:29.531413Z","iopub.status.idle":"2025-01-10T19:57:29.540902Z","shell.execute_reply.started":"2025-01-10T19:57:29.531361Z","shell.execute_reply":"2025-01-10T19:57:29.540128Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n# from spektral.layers import GraphSageConv\n\n# # Define input layers\n# bert_pool = tf.keras.Input(shape=(768,), dtype=tf.float64, name=\"query_text_input\")\n# adj_sp_tt = tf.keras.Input(shape=(256,), sparse=True, dtype=tf.float64, name=\"Adjacency_Matrix_Sparse\")\n\n# # Define GraphSAGE convolutional layer\n# gso = GraphSageConv(channels=782)([bert_pool, adj_sp_tt])\n\n# do = Dense(782, activation=\"relu\", name=\"Dense_Layer_1\")(gso)\n# do = BatchNormalization()(do)\n# do = Dropout(0.3)(do)\n\n# do = Dense(512, activation=\"relu\", name=\"Dense_Layer_2\")(do)\n# do = BatchNormalization()(do)\n# do = Dropout(0.3)(do)\n\n# # Final Dense layers leading to output\n# do = Dense(256, activation=\"relu\", name=\"Dense_Layer_3\")(do)\n# do = BatchNormalization()(do)\n# do = Dropout(0.3)(do)\n\n# do = Dense(128, activation=\"relu\", name=\"Dense_Layer_4\")(do)\n# do = BatchNormalization()(do)\n# do = Dropout(0.3)(do)\n\n# do = Dense(64, activation=\"relu\", name=\"Dense_Layer_5\")(do)\n# do = BatchNormalization()(do)\n# do = Dropout(0.3)(do)\n\n# do = Dense(32, activation=\"relu\", name=\"Dense_Layer_6\")(do)\n# do = BatchNormalization()(do)\n# do = Dropout(0.3)(do)\n\n# # Output layer\n# fdo = Dense(2, activation=\"softmax\", name=\"Output_Layer_7\")(do)\n\n# # Define the model\n# model = tf.keras.Model(inputs=[bert_pool, adj_sp_tt], outputs=fdo)\n\n# # Define your optimizer and loss function\n# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n# loss_fn = tf.keras.losses.CategoricalCrossentropy()\n\n# # Place the model on GPU\n# with tf.device('/device:GPU:0'):\n#     model_on_gpu = model\n\n# # Display model summary\n\n# model_on_gpu.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n# model_on_gpu.summary()","metadata":{"id":"pOTVojYwgD06","outputId":"24fde7ab-bc50-42b1-d27d-8611c202823c","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:29.542693Z","iopub.execute_input":"2025-01-10T19:57:29.542976Z","iopub.status.idle":"2025-01-10T19:57:29.557037Z","shell.execute_reply.started":"2025-01-10T19:57:29.542950Z","shell.execute_reply":"2025-01-10T19:57:29.556310Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\nfrom spektral.layers import GraphSageConv\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, LeakyReLU, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n# Define input layers\nbert_pool = tf.keras.Input(shape=(768,), dtype=tf.float32, name=\"query_text_input\")\nadj_sp_tt = tf.keras.Input(shape=(256,), sparse=True, dtype=tf.float32, name=\"Adjacency_Matrix_Sparse\")\n\ngso = GraphSageConv(channels=782)([bert_pool, adj_sp_tt])\n\n# Layer 1 (ReLU Activation)\ndo = Dense(782, kernel_initializer='he_uniform', name=\"Dense_Layer_1\")(gso)\ndo = BatchNormalization()(do)\ndo = Activation(\"relu\")(do)\ndo = Dropout(0.2)(do)\n\n# Layer 2 (LeakyReLU Activation)\ndo = Dense(512, kernel_initializer='he_uniform', name=\"Dense_Layer_2\")(do)\ndo = BatchNormalization()(do)\ndo = LeakyReLU(alpha=0.1)(do)  # LeakyReLU allows gradient flow for negative values\ndo = Dropout(0.2)(do)\n\n# Layer 3 (ELU Activation)\ndo = Dense(256, kernel_initializer='he_uniform', name=\"Dense_Layer_3\")(do)\ndo = BatchNormalization()(do)\ndo = Activation(\"elu\")(do)  # ELU improves convergence speed and performance\ndo = Dropout(0.2)(do)\n\n# Layer 4 (GELU Activation)\ndo = Dense(128, kernel_initializer='he_uniform', name=\"Dense_Layer_4\")(do)\ndo = BatchNormalization()(do)\ndo = Activation(\"gelu\")(do)  # GELU is smoother than ReLU for high performance in deep layers\ndo = Dropout(0.2)(do)\n\n# Layer 5 (tanh Activation)\ndo = Dense(64, kernel_initializer='he_uniform', name=\"Dense_Layer_5\")(do)\ndo = BatchNormalization()(do)\ndo = Activation(\"tanh\")(do)  # Tanh may help in lower-dimension spaces\ndo = Dropout(0.2)(do)\n\n# Layer 6 (ReLU Activation)\ndo = Dense(32, kernel_initializer='he_uniform', name=\"Dense_Layer_6\")(do)\ndo = BatchNormalization()(do)\ndo = Activation(\"relu\")(do)\ndo = Dropout(0.2)(do)\n\n# Output layer\nfdo = Dense(2, activation=\"softmax\", name=\"Output_Layer_7\")(do)\n\n# Define the model\nmodel = tf.keras.Model(inputs=[bert_pool, adj_sp_tt], outputs=fdo, name=\"Fully_Optimized_Model\")\n\n# Define your optimizer and loss function\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\nloss_fn = tf.keras.losses.CategoricalCrossentropy()\n\n# Compile the model\nmodel.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n\n# Display model summary\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:29.558136Z","iopub.execute_input":"2025-01-10T19:57:29.558390Z","iopub.status.idle":"2025-01-10T19:57:29.843587Z","shell.execute_reply.started":"2025-01-10T19:57:29.558366Z","shell.execute_reply":"2025-01-10T19:57:29.842619Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"Fully_Optimized_Model\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Fully_Optimized_Model\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ query_text_input    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Adjacency_Matrix_S… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ graph_sage_conv_2   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m782\u001b[0m)       │  \u001b[38;5;34m1,201,934\u001b[0m │ query_text_input… │\n│ (\u001b[38;5;33mGraphSageConv\u001b[0m)     │                   │            │ Adjacency_Matrix… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m782\u001b[0m)       │    \u001b[38;5;34m612,306\u001b[0m │ graph_sage_conv_… │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m782\u001b[0m)       │      \u001b[38;5;34m3,128\u001b[0m │ Dense_Layer_1[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m782\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m782\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m400,896\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │      \u001b[38;5;34m2,048\u001b[0m │ Dense_Layer_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ leaky_re_lu_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_2[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ Dense_Layer_3[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m512\u001b[0m │ Dense_Layer_4[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m256\u001b[0m │ Dense_Layer_5[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_13       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_16          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ activation_13[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m128\u001b[0m │ Dense_Layer_6[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_14       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_17          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ activation_14[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Output_Layer_7      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m66\u001b[0m │ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ query_text_input    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Adjacency_Matrix_S… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ graph_sage_conv_2   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">782</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,201,934</span> │ query_text_input… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GraphSageConv</span>)     │                   │            │ Adjacency_Matrix… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">782</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">612,306</span> │ graph_sage_conv_… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">782</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,128</span> │ Dense_Layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">782</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">782</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">400,896</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ Dense_Layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ leaky_re_lu_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ Dense_Layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ Dense_Layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ Dense_Layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_13       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_16          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Dense_Layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ Dense_Layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ activation_14       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_17          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ Output_Layer_7      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,396,858\u001b[0m (9.14 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,396,858</span> (9.14 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,393,310\u001b[0m (9.13 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,393,310</span> (9.13 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,548\u001b[0m (13.86 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,548</span> (13.86 KB)\n</pre>\n"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"all_gsc_enc = []\n\nimport tensorflow as tf\nfrom tensorflow.keras.utils import custom_object_scope\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nimport tensorflow as tf\nfrom tqdm import tqdm\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import accuracy_score","metadata":{"id":"hZrzRAfTlB-K","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:29.844882Z","iopub.execute_input":"2025-01-10T19:57:29.845632Z","iopub.status.idle":"2025-01-10T19:57:29.850200Z","shell.execute_reply.started":"2025-01-10T19:57:29.845590Z","shell.execute_reply":"2025-01-10T19:57:29.849252Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Load train data\nX_train_data = np.load(\"/kaggle/input/pan-dataset/bert_train_embeddings.npy\")\nX_train_out = np.load(\"/kaggle/input/pan-output/train_labels.npy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:29.851475Z","iopub.execute_input":"2025-01-10T19:57:29.852276Z","iopub.status.idle":"2025-01-10T19:57:30.268434Z","shell.execute_reply.started":"2025-01-10T19:57:29.852235Z","shell.execute_reply":"2025-01-10T19:57:30.267455Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# Load test data\nX_test_data = np.load(\"/kaggle/input/pan-dataset/bert_test_embeddings.npy\")\nX_test_out = np.load(\"/kaggle/input/pan-out/test_target.npy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:30.269680Z","iopub.execute_input":"2025-01-10T19:57:30.269955Z","iopub.status.idle":"2025-01-10T19:57:30.529216Z","shell.execute_reply.started":"2025-01-10T19:57:30.269930Z","shell.execute_reply":"2025-01-10T19:57:30.528501Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# Load val data\nX_val_data = np.load(\"/kaggle/input/pan-dataset/bert_val_embeddings.npy\")\nX_val_out = np.load(\"/kaggle/input/pan-out/val_target.npy\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:30.530281Z","iopub.execute_input":"2025-01-10T19:57:30.530563Z","iopub.status.idle":"2025-01-10T19:57:30.567562Z","shell.execute_reply.started":"2025-01-10T19:57:30.530537Z","shell.execute_reply":"2025-01-10T19:57:30.566816Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.utils import shuffle\n\n# Shuffle train data and labels\nX_train_data, X_train_out = shuffle(X_train_data, X_train_out, random_state=42)\n\n# Shuffle test data and labels\nX_test_data, X_test_out = shuffle(X_test_data, X_test_out, random_state=42)\n\n# Shuffle val data and labels\nX_val_data, X_val_out = shuffle(X_val_data, X_val_out, random_state=42)\n\n# Reshape outputs for model compatibility\nX_train_out = X_train_out.reshape(-1, 1)\nX_test_out = X_test_out.reshape(-1, 1)\nX_val_out = X_val_out.reshape(-1, 1)\n\n# Shuffle train data and labels\nX_train_data, X_train_out = shuffle(X_train_data, X_train_out, random_state=42)\n\n# Shuffle test data and labels\nX_test_data, X_test_out = shuffle(X_test_data, X_test_out, random_state=42)\n\n# Shuffle val data and labels\nX_val_data, X_val_out = shuffle(X_val_data, X_val_out, random_state=42)\n\n# Reshape outputs for model compatibility\nX_train_out = X_train_out.reshape(-1, 1)\nX_test_out = X_test_out.reshape(-1, 1)\nX_val_out = X_val_out.reshape(-1, 1)","metadata":{"id":"dCgZ3Nedq5iW","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:30.570328Z","iopub.execute_input":"2025-01-10T19:57:30.570961Z","iopub.status.idle":"2025-01-10T19:57:32.012052Z","shell.execute_reply.started":"2025-01-10T19:57:30.570930Z","shell.execute_reply":"2025-01-10T19:57:32.011278Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Define the number of epochs and batch size\nnum_epochs = 100\nbatch_size = 256\n\n# Prepare batches for train data\nX_train_data_batches = create_batches(X_train_data, batch_size)\nX_train_out_batches = create_batches(X_train_out, batch_size)\n\n# Prepare batches for test data\nX_test_data_batches = create_batches(X_test_data, batch_size)\nX_test_out_batches = create_batches(X_test_out, batch_size)\n\n# Prepare batches for test data\nX_val_data_batches = create_batches(X_val_data, batch_size)\nX_val_out_batches = create_batches(X_val_out, batch_size)","metadata":{"id":"CpF-PDw_-xLh","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:32.013203Z","iopub.execute_input":"2025-01-10T19:57:32.013491Z","iopub.status.idle":"2025-01-10T19:57:32.031278Z","shell.execute_reply.started":"2025-01-10T19:57:32.013465Z","shell.execute_reply":"2025-01-10T19:57:32.030400Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"import tensorflow as tf\nfrom tqdm import tqdm\n\n# Initialize variables for accuracy and loss tracking\ntotal_correct = 0\ntotal_samples = 0\ntotal_loss = 0\n\n# Check if GPU is available\ndevice = '/gpu:0' if tf.config.list_physical_devices('GPU') else '/cpu:0'\nprint(f\"Using device: {device}\")\n\n# Training loop with testing after every epoch\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n\n    # Initialize variables to keep track of accuracy and loss for training\n    total_correct_train = 0\n    total_samples_train = 0\n    total_loss_train = 0\n\n    # Training loop\n    for i in range(len(X_train_data_batches)):\n        batch_train_data = tf.convert_to_tensor(X_train_data_batches[i], dtype=tf.float32)\n        batch_train_out = tf.convert_to_tensor(X_train_out_batches[i], dtype=tf.int32)\n\n        adj_train, adj_train_sparse = get_adj(batch_train_data)\n\n        # Reshape batch_out and convert to one-hot encoding\n        batch_train_out = tf.reshape(batch_train_out, [-1])\n        batch_train_out_one_hot = tf.one_hot(batch_train_out, depth=2)\n\n        with tf.device(device):\n            with tf.GradientTape() as tape:\n                predictions = model(\n                    [batch_train_data, adj_train_sparse],\n                    training=True\n                )\n                loss_value = loss_fn(batch_train_out_one_hot, predictions)\n\n            # Compute gradients and update weights\n            gradients = tape.gradient(loss_value, model.trainable_variables)\n            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n            # Update metrics\n            total_loss_train += loss_value.numpy() * len(batch_train_data)\n            total_correct_train += tf.reduce_sum(\n                tf.cast(tf.equal(tf.argmax(predictions, axis=1), tf.cast(batch_train_out, tf.int64)), tf.float32)\n            ).numpy()\n            total_samples_train += len(batch_train_data)\n\n    # Calculate epoch-level training metrics\n    epoch_accuracy_train = total_correct_train / total_samples_train\n    epoch_loss_train = total_loss_train / total_samples_train\n    print(f\"Training Accuracy: {epoch_accuracy_train:.4f}\")\n    print(f\"Training Loss: {epoch_loss_train:.4f}\")\n\n    # Testing after each epoch\n    total_correct_test = 0\n    total_samples_test = 0\n    total_loss_test = 0\n\n    for i in tqdm(range(len(X_test_data_batches))):\n        batch_test_data = tf.convert_to_tensor(X_test_data_batches[i], dtype=tf.float32)\n        batch_test_out = tf.convert_to_tensor(X_test_out_batches[i], dtype=tf.int32)\n       \n\n        test_adj, test_adj_sparse = get_adj(batch_test_data)\n\n        # Reshape batch_test_out and convert to one-hot encoding\n        batch_test_out = tf.reshape(batch_test_out, [-1])\n        batch_out_one_hot = tf.one_hot(batch_test_out, depth=2)\n\n        with tf.device(device):\n            # Get predictions from the model\n            predictions = model(\n                [batch_test_data, test_adj_sparse],\n                training=False\n            )\n            loss_value = loss_fn(batch_out_one_hot, predictions)\n\n            # Update metrics\n            total_loss_test += loss_value.numpy() * len(batch_test_data)\n            total_correct_test += tf.reduce_sum(\n                tf.cast(tf.equal(tf.argmax(predictions, axis=1), tf.cast(batch_test_out, tf.int64)), tf.float32)\n            ).numpy()\n            total_samples_test += len(batch_test_data)\n\n    # Calculate test metrics\n    test_accuracy = total_correct_test / total_samples_test\n    test_loss = total_loss_test / total_samples_test\n    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n    print(f\"Test Loss: {test_loss:.4f}\")\n\n    # Validation after each epoch\n    total_correct_val = 0\n    total_samples_val = 0\n    total_loss_val = 0\n\n    for i in tqdm(range(len(X_val_data_batches))):\n        batch_val_data = tf.convert_to_tensor(X_val_data_batches[i], dtype=tf.float32)\n        batch_val_out = tf.convert_to_tensor(X_val_out_batches[i], dtype=tf.int32)\n\n        val_adj, val_adj_sparse = get_adj(batch_val_data)\n\n        # Reshape batch_val_out and convert to one-hot encoding\n        batch_val_out = tf.reshape(batch_val_out, [-1])\n        batch_out_one_hot = tf.one_hot(batch_val_out, depth=2)\n\n        with tf.device(device):\n            # Get predictions from the model\n            predictions = model(\n                [batch_val_data, val_adj_sparse],\n                training=False\n            )\n            loss_value = loss_fn(batch_out_one_hot, predictions)\n\n            # Update metrics\n            total_loss_val += loss_value.numpy() * len(batch_val_data)\n            total_correct_val += tf.reduce_sum(\n                tf.cast(tf.equal(tf.argmax(predictions, axis=1), tf.cast(batch_val_out, tf.int64)), tf.float32)\n            ).numpy()\n            total_samples_val += len(batch_val_data)\n\n    # Calculate val metrics\n    val_accuracy = total_correct_val / total_samples_val\n    val_loss = total_loss_val / total_samples_val\n    print(f\"Val Accuracy: {val_accuracy:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}\")\n\n    # Save model if both test and validation accuracies exceed 98%\n    if test_accuracy > 0.95 and val_accuracy > 0.95:\n        model.save(f'/kaggle/working/model_epoch_{epoch + 1}.h5')\n        print(f\"Model saved at epoch {epoch + 1} with Test Accuracy: {test_accuracy:.4f} and Val Accuracy: {val_accuracy:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RhzfDQrTBznj","outputId":"0e13f139-c7b6-4e6d-c345-0eab3fc7ab08","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:32.032771Z","iopub.execute_input":"2025-01-10T19:57:32.033279Z","iopub.status.idle":"2025-01-10T19:57:32.043996Z","shell.execute_reply.started":"2025-01-10T19:57:32.033241Z","shell.execute_reply":"2025-01-10T19:57:32.043225Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nimport os\nimport re\n\n# Directory where saved models are stored\nmodel_dir = '/kaggle/input/best-models'  # Change this to your saved models directory\nmodel_pattern = r'model_epoch_(\\d+)\\.h5'\n\n# Initialize lists for storing classification reports\nclassification_reports = []\n\n# Load all saved models and iterate\nfor filename in os.listdir(model_dir):\n    if re.match(model_pattern, filename):\n        epoch_number = int(re.search(model_pattern, filename).group(1))\n        model_path = os.path.join(model_dir, filename)\n        model = tf.keras.models.load_model(model_path, custom_objects={'GraphSageConv': GraphSageConv})\n\n        # Evaluate model on test dataset\n        y_test_true = []\n        y_test_pred = []\n\n        for i in tqdm(range(len(X_test_data_batches))):\n            batch_test_data = tf.convert_to_tensor(X_test_data_batches[i], dtype=tf.float32)\n            batch_test_out = tf.convert_to_tensor(X_test_out_batches[i], dtype=tf.int32)\n\n            test_adj, test_adj_sparse = get_adj(batch_test_data)\n\n            # Predictions\n            predictions = model(\n                [batch_test_data, test_adj_sparse], training=False)\n            y_test_true.extend(batch_test_out.numpy())\n            y_test_pred.extend(tf.argmax(predictions, axis=1).numpy())\n\n        # Generate test classification report\n        test_report = classification_report(y_test_true, y_test_pred, output_dict=True)\n        test_overall_accuracy = test_report['accuracy']\n        classification_reports.append({'Epoch': epoch_number, 'Phase': 'Test', 'Report': test_report, 'Accuracy': test_overall_accuracy})\n\n        # Evaluate model on validation dataset\n        y_val_true = []\n        y_val_pred = []\n\n        for i in tqdm(range(len(X_val_data_batches))):\n            batch_val_data = tf.convert_to_tensor(X_val_data_batches[i], dtype=tf.float32)\n            batch_val_out = tf.convert_to_tensor(X_val_out_batches[i], dtype=tf.int32)\n\n            val_adj, val_adj_sparse = get_adj(batch_val_data)\n\n            # Predictions\n            predictions = model(\n                [batch_val_data, val_adj_sparse], training=False)\n            y_val_true.extend(batch_val_out.numpy())\n            y_val_pred.extend(tf.argmax(predictions, axis=1).numpy())\n\n        # Generate validation classification report\n        val_report = classification_report(y_val_true, y_val_pred, output_dict=True)\n        val_overall_accuracy = val_report['accuracy']\n        classification_reports.append({'Epoch': epoch_number, 'Phase': 'Validation', 'Report': val_report, 'Accuracy': val_overall_accuracy})\n\n# Save all classification reports to a CSV\nrows = []\nfor report in classification_reports:\n    epoch = report['Epoch']\n    phase = report['Phase']\n    overall_accuracy = report['Accuracy']\n    for class_name, metrics in report['Report'].items():\n        if class_name in ['accuracy', 'macro avg', 'weighted avg']:\n            continue\n        rows.append({\n            'Epoch': epoch,\n            'Phase': phase,\n            'Class': class_name,\n            'Precision': metrics['precision'],\n            'Recall': metrics['recall'],\n            'F1-Score': metrics['f1-score'],\n            'Support': metrics['support'],\n            'Overall Accuracy': overall_accuracy\n        })\n\n# Create a DataFrame and save as CSV\ndf = pd.DataFrame(rows)\ndf.to_csv('/kaggle/working/classification_reports.csv', index=False)\nprint(\"Classification reports saved to classification_reports.csv\")","metadata":{"id":"SgE0-bZt7qWU","trusted":true,"execution":{"iopub.status.busy":"2025-01-10T19:57:32.045500Z","iopub.execute_input":"2025-01-10T19:57:32.045802Z","iopub.status.idle":"2025-01-10T20:00:11.579827Z","shell.execute_reply.started":"2025-01-10T19:57:32.045774Z","shell.execute_reply":"2025-01-10T20:00:11.578919Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 1009/1009 [01:19<00:00, 12.68it/s]\n100%|██████████| 99/99 [00:07<00:00, 12.64it/s]\n100%|██████████| 1009/1009 [01:02<00:00, 16.19it/s]\n100%|██████████| 99/99 [00:07<00:00, 12.95it/s]","output_type":"stream"},{"name":"stdout","text":"Classification reports saved to classification_reports.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":42}]}